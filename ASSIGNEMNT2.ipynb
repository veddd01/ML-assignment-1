{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e281bde5",
   "metadata": {},
   "source": [
    "The Marketing department of Adventure Works Cycles wants to increase sales by targeting specific customers for a mailing campaign. The company's database contains a list of past customers and a list of potential new customers. By investigating the attributes of previous bike buyers, the company hopes to discover patterns that they can then apply to potential customers. They hope to use the discovered patterns to predict which potential customers are most likely to purchase a bike from Adventure Works Cycles.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2a9e50",
   "metadata": {},
   "source": [
    "Part I: Based on Feature Selection, Cleaning, and Preprocessing to Construct an Input from Data Source \n",
    "(a)\tExamine the values of each attribute and Select a set of attributes only that would affect to predict future bike buyers to create your input for data mining algorithms. Remove all the unnecessary attributes. (Select features just by analysis). \n",
    "(b)\tCreate a new Data Frame with the selected attributes only. \n",
    "(c)\tDetermine a Data value type (Discrete, or Continuous, then Nominal, Ordinal, Interval, Ratio) of each attribute in your selection to identify preprocessing tasks to create input for your data mining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799eec8",
   "metadata": {},
   "source": [
    "PART I(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee12933",
   "metadata": {},
   "source": [
    "We look at the dataset AWcustomers.csv and AWsales.csv . Typical columns inside are:-\n",
    "\n",
    "1.CustomerID → Just an identifier (not useful for prediction).\n",
    "\n",
    "2.FirstName, LastName, Address, City, State, Country, PostalCode, PhoneNumber, Email → Personal details (not useful).\n",
    "\n",
    "3.MaritalStatus (M/S) → Could matter (married people may buy differently).\n",
    "\n",
    "4.Gender (M/F) → Might affect purchase.\n",
    "\n",
    "5.Education (High School, Bachelors, Graduate, Partial College, etc.) → Important.\n",
    "\n",
    "6.Occupation (Skilled, Professional, Clerical, Manual, Management, etc.) → Important.\n",
    "\n",
    "7.HouseOwnerFlag (1/0) → Owning a house may indicate income level.\n",
    "\n",
    "8.NumberCarsOwned → Lifestyle indicator.\n",
    "\n",
    "9.NumberChildrenAtHome → Family size → important.\n",
    "\n",
    "10.TotalChildren → Family size (keep one of these).\n",
    "\n",
    "11.YearlyIncome → Very important.\n",
    "\n",
    "12.CommuteDistance (0-1 mile, 2-5 miles, 5-10 miles, 10+ miles, etc.) → Very important.\n",
    "\n",
    "13.Region → Location effect.\n",
    "\n",
    "14.Age → Very important.\n",
    "\n",
    "15.AvgMonthSpend ->indicates customer spending behavior, very useful for predicting buying intent.\n",
    "\n",
    "16.BikeBuyer (0/1) → Target variable (whether customer bought a bike).\n",
    "\n",
    "So, we drop unnecessary columns (like IDs, names, emails, phone numbers, postal codes, etc.) and keep only meaningful attributes.\n",
    "\n",
    "\n",
    "Selected Features:\n",
    "\n",
    "\n",
    "1.Age\n",
    "\n",
    "2.Gender\n",
    "\n",
    "3.MaritalStatus\n",
    "\n",
    "4.Education\n",
    "\n",
    "5.Occupation\n",
    "\n",
    "6.HouseOwnerFlag\n",
    "\n",
    "7.NumberCarsOwned\n",
    "\n",
    "8.NumberChildrenAtHome\n",
    "\n",
    "9.YearlyIncome\n",
    "\n",
    "10.CommuteDistance\n",
    "\n",
    "11.Region\n",
    "\n",
    "12.AvgMonthSpend \n",
    "\n",
    "13.BikeBuyer (target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d610f4d",
   "metadata": {},
   "source": [
    "PART I(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e28af4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Data (first 5 rows):\n",
      "   Age Gender MaritalStatus        Education      Occupation  HomeOwnerFlag  \\\n",
      "0   37      M             M        Bachelors        Clerical              1   \n",
      "1   53      M             M  Partial College        Clerical              1   \n",
      "2   39      F             S        Bachelors        Clerical              0   \n",
      "3   47      M             M  Partial College  Skilled Manual              1   \n",
      "4   50      M             S  Partial College  Skilled Manual              1   \n",
      "\n",
      "   NumberCarsOwned  NumberChildrenAtHome  TotalChildren  YearlyIncome  \\\n",
      "0                3                     0              1         81916   \n",
      "1                2                     1              2         81076   \n",
      "2                3                     0              0         86387   \n",
      "3                2                     1              2         61481   \n",
      "4                1                     0              0         51804   \n",
      "\n",
      "   BikeBuyer  AvgMonthSpend  \n",
      "0          1          50.97  \n",
      "1          1          53.11  \n",
      "2          1          54.08  \n",
      "3          1          56.93  \n",
      "4          1          55.41  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both datasets\n",
    "customers = pd.read_csv(\"AWcustomers.csv\")\n",
    "sales = pd.read_csv(\"AWsales.csv\")\n",
    "\n",
    "df = pd.merge(customers, sales, on=\"CustomerID\", how=\"inner\")\n",
    "\n",
    "selected_features = [\n",
    "    \"Age\",                # calculated below\n",
    "    \"Gender\",\n",
    "    \"MaritalStatus\",\n",
    "    \"Education\",\n",
    "    \"Occupation\",\n",
    "    \"HomeOwnerFlag\",\n",
    "    \"NumberCarsOwned\",\n",
    "    \"NumberChildrenAtHome\",\n",
    "    \"TotalChildren\",\n",
    "    \"YearlyIncome\",\n",
    "    \"BikeBuyer\",\n",
    "    \"AvgMonthSpend\"  \n",
    "]\n",
    "\n",
    "df[\"BirthDate\"] = pd.to_datetime(df[\"BirthDate\"], format=\"%d-%m-%Y\", errors=\"coerce\")\n",
    "df[\"Age\"] = (pd.Timestamp(\"today\") - df[\"BirthDate\"]).dt.days // 365\n",
    "\n",
    "df_selected = df[selected_features]\n",
    "\n",
    "print(\"Selected Data (first 5 rows):\")\n",
    "print(df_selected.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da04f4a6",
   "metadata": {},
   "source": [
    "PART I(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7622635",
   "metadata": {},
   "source": [
    "\n",
    "| Attribute            | Data Type          | Notes                                      |\n",
    "| -------------------- | ------------------ | ------------------------------------------ |\n",
    "| Age                  | Continuous (Ratio) | Numeric, calculated from BirthDate         |\n",
    "| Gender               | Nominal            | Categorical (M/F)                          |\n",
    "| MaritalStatus        | Nominal            | (S/M)                                      |\n",
    "| Education            | Ordinal            | (High School < Bachelors < Graduate, etc.) |\n",
    "| Occupation           | Nominal            | Clerical, Skilled Manual, etc.             |\n",
    "| HomeOwnerFlag        | Binary (Nominal)   | 0/1                                        |\n",
    "| NumberCarsOwned      | Discrete (Ratio)   | Integer count                              |\n",
    "| NumberChildrenAtHome | Discrete (Ratio)   | Integer count                              |\n",
    "| TotalChildren        | Discrete (Ratio)   | Integer count                              |\n",
    "| YearlyIncome         | Continuous (Ratio) | Numeric                                    |\n",
    "| BikeBuyer            | Binary (Nominal)   | Target variable                            |\n",
    "| AvgMonthSpend        | Continuous (Ratio) | Numeric                                    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2178b56d",
   "metadata": {},
   "source": [
    "Part II: Data Preprocessing and Transformation \n",
    "Depending on the data type of each attribute, transform each object from your preprocessed data.  \n",
    "Use all the data rows (~= 18000 rows) with the selected features as input to apply all the tasks below, do not perform each task on the smaller data set that you got from your random sampling result.  \n",
    "(a)\tHandling Null values \n",
    "(b)\tNormalization  \n",
    "(c)\tDiscretization (Binning) on Continuous attributes or Categorical Attributes with too many different values  \n",
    "(d)\tStandardization/Normalization \n",
    "(e)\tBinarization (One Hot Encoding) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d422f678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data (first 5 rows):\n",
      "        Age HomeOwnerFlag NumberCarsOwned NumberChildrenAtHome TotalChildren  \\\n",
      "0 -0.542849             1               3                    0             1   \n",
      "1  0.876937             1               2                    1             2   \n",
      "2 -0.365376             0               3                    0             0   \n",
      "3  0.344517             1               2                    1             2   \n",
      "4  0.610727             1               1                    0             0   \n",
      "\n",
      "   YearlyIncome BikeBuyer  AvgMonthSpend  Gender_M  MaritalStatus_S  \\\n",
      "0      0.298555         1      -0.231774      True            False   \n",
      "1      0.271180         1       0.390755      True            False   \n",
      "2      0.444261         1       0.672929     False             True   \n",
      "3     -0.367401         1       1.501999      True            False   \n",
      "4     -0.682765         1       1.059828      True             True   \n",
      "\n",
      "   Education_Graduate Degree  Education_High School  \\\n",
      "0                      False                  False   \n",
      "1                      False                  False   \n",
      "2                      False                  False   \n",
      "3                      False                  False   \n",
      "4                      False                  False   \n",
      "\n",
      "   Education_Partial College  Education_Partial High School  \\\n",
      "0                      False                          False   \n",
      "1                       True                          False   \n",
      "2                      False                          False   \n",
      "3                       True                          False   \n",
      "4                       True                          False   \n",
      "\n",
      "   Occupation_Management  Occupation_Manual  Occupation_Professional  \\\n",
      "0                  False              False                    False   \n",
      "1                  False              False                    False   \n",
      "2                  False              False                    False   \n",
      "3                  False              False                    False   \n",
      "4                  False              False                    False   \n",
      "\n",
      "   Occupation_Skilled Manual  AgeGroup_Middle  AgeGroup_Senior  \n",
      "0                      False            False            False  \n",
      "1                      False            False            False  \n",
      "2                      False            False            False  \n",
      "3                       True            False            False  \n",
      "4                       True            False            False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "customers = pd.read_csv(\"AWcustomers.csv\")\n",
    "sales = pd.read_csv(\"AWsales.csv\")\n",
    "\n",
    "df = pd.merge(customers, sales, on=\"CustomerID\", how=\"inner\")\n",
    "\n",
    "df[\"BirthDate\"] = pd.to_datetime(df[\"BirthDate\"], format=\"%d-%m-%Y\", errors=\"coerce\")\n",
    "df[\"Age\"] = (pd.Timestamp(\"today\") - df[\"BirthDate\"]).dt.days // 365\n",
    "\n",
    "selected_features = [\n",
    "    \"Age\", \"Gender\", \"MaritalStatus\", \"Education\", \"Occupation\", \"HomeOwnerFlag\",\n",
    "    \"NumberCarsOwned\", \"NumberChildrenAtHome\", \"TotalChildren\", \"YearlyIncome\",\n",
    "    \"BikeBuyer\", \"AvgMonthSpend\"\n",
    "]\n",
    "df = df[selected_features]\n",
    "\n",
    "# (a) Handling NULL values\n",
    "imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# (b) Normalization\n",
    "scaler = MinMaxScaler()\n",
    "continuous = [\"Age\", \"YearlyIncome\", \"AvgMonthSpend\"]\n",
    "df_imputed[continuous] = scaler.fit_transform(df_imputed[continuous])\n",
    "\n",
    "# (c) Discretization (Binning) on Continuous attributes or Categorical Attributes with too many different values\n",
    "df_imputed[\"AgeGroup\"] = pd.cut(df_imputed[\"Age\"],\n",
    "                                bins=[0, 25, 50, 100],\n",
    "                                labels=[\"Young\", \"Middle\", \"Senior\"])\n",
    "\n",
    "# (d) Standardization/Normalization\n",
    "std_scaler = StandardScaler()\n",
    "df_imputed[continuous] = std_scaler.fit_transform(df_imputed[continuous])\n",
    "\n",
    "# (e) Binarization (One Hot Encoding)\n",
    "categorical = [\"Gender\", \"MaritalStatus\", \"Education\", \"Occupation\", \"AgeGroup\"]\n",
    "df_encoded = pd.get_dummies(df_imputed, columns=categorical, drop_first=True)\n",
    "\n",
    "print(\"Transformed Data (first 5 rows):\")\n",
    "print(df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd2e594",
   "metadata": {},
   "source": [
    "Part III: Calculating Proximity /Correlation Analysis of two features \n",
    "Make sure each attribute is transformed in a same scale for numeric attributes and Binarization for each nominal attribute, and each discretized numeric attribute to standardization. Make sure to apply a correct similarity measure for nominal (one hot encoding)/binary attributes and numeric attributes respectively. \n",
    "(a)\tCalculate Similarity in Simple Matching, Jaccard Similarity, and Cosine Similarity between two following objects of your transformed input data. \n",
    "(b)\tCalculate Correlation between two features Commute Distance and Yearly Income "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b30ed083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Matching: 0.6225695768204346\n",
      "Jaccard Similarity: 0.5097623089983022\n",
      "Cosine Similarity: 0.6761544705611521\n",
      "CommuteDistance not found in dataset\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "x = df_encoded[\"BikeBuyer\"].astype(int).values\n",
    "y = df_encoded[\"HomeOwnerFlag\"].astype(int).values\n",
    "\n",
    "# (a)Calculate Similarity in Simple Matching, Jaccard Similarity, and Cosine Similarity between two following objects of your transformed input data. \n",
    "simple_matching = np.mean(x == y)\n",
    "jaccard = jaccard_score(x, y)\n",
    "cosine = cosine_similarity(x.reshape(1, -1), y.reshape(1, -1))[0][0]\n",
    "\n",
    "print(\"Simple Matching:\", simple_matching)\n",
    "print(\"Jaccard Similarity:\", jaccard)\n",
    "print(\"Cosine Similarity:\", cosine)\n",
    "\n",
    "# (b)\tCalculate Correlation between two features Commute Distance and Yearly Income \n",
    "if \"CommuteDistance\" in df.columns:\n",
    "    corr = df[\"CommuteDistance\"].astype(float).corr(df[\"YearlyIncome\"].astype(float))\n",
    "    print(\"Correlation (CommuteDistance vs YearlyIncome):\", corr)\n",
    "else:\n",
    "    print(\"CommuteDistance not found in dataset\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
