{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68ce01f0",
   "metadata": {},
   "source": [
    "1)\tThe Iris dataset is a classic example for demonstrating classification algorithms. It consists of 150 samples of iris flowers belonging to three species: Setosa, Versicolor, and Virginica, with four input features (sepal and petal length/width). Use SVC from sklearn.svm on the Iris dataset and follow the steps below:\n",
    "\n",
    "a. Load the dataset and perform train–test split (80:20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aa1d689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (120, 4)\n",
      "X_test shape: (30, 4)\n",
      "y_train shape: (120,)\n",
      "y_test shape: (30,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f4f51b",
   "metadata": {},
   "source": [
    "b. Train three different SVM models using the following kernels:\n",
    "Linear, Polynomial (degree=3), RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edeb9794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models trained: Linear, Polynomial (degree=3), RBF\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "svm_linear = SVC(kernel=\"linear\")\n",
    "svm_poly = SVC(kernel=\"poly\", degree=3)\n",
    "svm_rbf = SVC(kernel=\"rbf\")\n",
    "\n",
    "svm_linear.fit(X_train, y_train)\n",
    "svm_poly.fit(X_train, y_train)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Models trained: Linear, Polynomial (degree=3), RBF\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8759d1c5",
   "metadata": {},
   "source": [
    "c. Evaluate each model using:\n",
    "    •\tAccuracy\n",
    "    •\tPrecision\n",
    "    •\tRecall\n",
    "    •\tF1-Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4af60e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel: Linear\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Kernel: Polynomial\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Kernel: RBF\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Linear\": SVC(kernel=\"linear\"),\n",
    "    \"Polynomial\": SVC(kernel=\"poly\", degree=3),\n",
    "    \"RBF\": SVC(kernel=\"rbf\")\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    rec = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    print(\"\\nKernel:\", name)\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Precision:\", prec)\n",
    "    print(\"Recall:\", rec)\n",
    "    print(\"F1-Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baf2f1c",
   "metadata": {},
   "source": [
    "d.Display the confusion matrix for each kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c904e8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel: Linear\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Kernel: Polynomial\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Kernel: RBF\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Linear\": SVC(kernel=\"linear\"),\n",
    "    \"Polynomial\": SVC(kernel=\"poly\", degree=3),\n",
    "    \"RBF\": SVC(kernel=\"rbf\")\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\nKernel:\", name)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9660141d",
   "metadata": {},
   "source": [
    "e.Identify which kernel performs the best and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d910f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: Linear | F1-Score: 1.0\n",
      "Kernel: Polynomial | F1-Score: 1.0\n",
      "Kernel: RBF | F1-Score: 1.0\n",
      "\n",
      "Best kernel based on F1-Score: Linear\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Linear\": SVC(kernel=\"linear\"),\n",
    "    \"Polynomial\": SVC(kernel=\"poly\", degree=3),\n",
    "    \"RBF\": SVC(kernel=\"rbf\")\n",
    "}\n",
    "\n",
    "f1_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    f1_scores[name] = f1\n",
    "    print(\"Kernel:\", name, \"| F1-Score:\", f1)\n",
    "\n",
    "best_kernel = max(f1_scores, key=f1_scores.get)\n",
    "print(\"\\nBest kernel based on F1-Score:\", best_kernel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bfcffb",
   "metadata": {},
   "source": [
    "2)\tSVM models are highly sensitive to the scale of input features. When features have different ranges, the algorithm may incorrectly assign higher importance to variables with larger magnitudes, affecting the placement of the separating hyperplane. Feature scaling ensures that all attributes contribute equally to distance-based computations, which is especially crucial for kernels like RBF or polynomial.\n",
    "\n",
    "A.  Use the Breast Cancer dataset from sklearn.datasets.load_breast_cancer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3736b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (455, 30)\n",
      "X_test: (114, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5451636e",
   "metadata": {},
   "source": [
    "B. Train an SVM (RBF kernel) model with and without feature scaling (StandardScaler). Compare both results using:\n",
    "    •\tTraining accuracy\n",
    "    •\tTesting accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89c5bea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy without scaling: 0.9142857142857143\n",
      "Testing accuracy without scaling: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = SVC(kernel=\"rbf\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_acc = model.score(X_train, y_train)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "\n",
    "print(\"Training accuracy without scaling:\", train_acc)\n",
    "print(\"Testing accuracy without scaling:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d2f256",
   "metadata": {},
   "source": [
    "Code for SVM WITH Feature Scaling (StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy with scaling: 0.989010989010989\n",
      "Testing accuracy with scaling: 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = SVC(kernel=\"rbf\")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "train_acc = model.score(X_train_scaled, y_train)\n",
    "test_acc = model.score(X_test_scaled, y_test)\n",
    "\n",
    "print(\"Training accuracy with scaling:\", train_acc)\n",
    "print(\"Testing accuracy with scaling:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b186bd49",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97f0313",
   "metadata": {},
   "source": [
    "Effect of Feature Scaling on SVM (RBF Kernel)\n",
    "SVM with RBF kernel is distance-based, so features must be on the same scale.\n",
    "Without scaling, large-range features dominate distance calculations → poor accuracy.\n",
    "With scaling, all features contribute equally → better margin and smoother boundary.\n",
    "\n",
    "As a result:-\n",
    "Training accuracy increases\n",
    "Testing accuracy increases\n",
    "Overfitting reduces\n",
    "\n",
    "In almost all datasets, SVM with scaling performs significantly better than without scaling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
